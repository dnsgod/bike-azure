import os
from pathlib import Path

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import pyodbc
from dotenv import load_dotenv

# -----------------------------
# Matplotlib í•œê¸€ ê¹¨ì§ ë°©ì§€ (Windows)
# -----------------------------
plt.rcParams["font.family"] = "Malgun Gothic"
plt.rcParams["axes.unicode_minus"] = False

st.set_page_config(page_title="ë”°ë¦‰ì´ ëª¨ë‹ˆí„°ë§", layout="wide")

# -----------------------------
# 0) í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (.env)
# -----------------------------
# ë°˜ë“œì‹œ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì—ì„œ ì‹¤í–‰: streamlit run app/app.py
load_dotenv()

SQL_SERVER = os.getenv("SQL_SERVER")
SQL_DB     = os.getenv("SQL_DB")
SQL_UID    = os.getenv("SQL_UID")
SQL_PWD    = os.getenv("SQL_PWD")

ODBC_DRIVER_CANDIDATES = [
    "ODBC Driver 18 for SQL Server",
    "ODBC Driver 17 for SQL Server",
]

# -----------------------------
# 1) â€œí‘œì‹œìš©â€ í•œê¸€ ì»¬ëŸ¼ ë§¤í•‘
# -----------------------------
KOR_COLS = {
    "station_id": "ëŒ€ì—¬ì†Œ ID",
    "station_name": "ëŒ€ì—¬ì†Œëª…",
    "bike_count": "ì£¼ì°¨ëœ ìì „ê±° ìˆ˜",
    "bikes_available": "ì£¼ì°¨ëœ ìì „ê±° ìˆ˜",
    "rack_tot_cnt": "ê±°ì¹˜ëŒ€ ìˆ˜",
    "parking_bike_tot_cnt": "ì£¼ì°¨ëœ ìì „ê±° ìˆ˜(ì›ë³¸)",
    "slots_available": "ë¹ˆ ê±°ì¹˜ëŒ€ ìˆ˜",
    "avail_ratio": "ê°€ìš©ë¥ ",
    "occ_ratio": "ì ìœ ìœ¨",
    "lat": "ìœ„ë„",
    "lon": "ê²½ë„",
    "ts_utc": "ìˆ˜ì§‘ì‹œê°(UTC)",
    "ts_kst_str": "ìˆ˜ì§‘ì‹œê°(KST)",
}

KOR_COLS_EXTRA = {
    "hour_utc": "ì‹œê°„(UTC)",
    "hour_kst": "ì‹œê°„(KST)",
    "availability_pct": "í‰ê·  ê°€ìš©ë¥ (%)",
    "avg_slots_available": "í‰ê·  ë¹ˆ ê±°ì¹˜ëŒ€ ìˆ˜",
    "avg_rack_capacity": "í‰ê·  ê±°ì¹˜ëŒ€ ìˆ˜",
    "need_relocation": "ì¬ë°°ì¹˜ í•„ìš”",
}

DISPLAY_COLS = {**KOR_COLS, **KOR_COLS_EXTRA}


def display_df(df: pd.DataFrame) -> pd.DataFrame:
    """í™”ë©´ ì¶œë ¥ìš©: ì»¬ëŸ¼ëª…ì„ í•œê¸€ë¡œ ë°”ê¾¼ ë·°"""
    if df is None or df.empty:
        return df
    return df.rename(columns=DISPLAY_COLS)


# -----------------------------
# 2) ODBC ì—°ê²° ë¬¸ìì—´
# -----------------------------
def _pick_driver():
    drivers = [d.strip() for d in pyodbc.drivers()]
    for name in ODBC_DRIVER_CANDIDATES:
        if name in drivers:
            return name
    raise RuntimeError(f"SQL Server ODBC driver not found. installed={drivers}")


def make_conn_str() -> str:
    missing = [k for k, v in {
        "SQL_SERVER": SQL_SERVER,
        "SQL_DB": SQL_DB,
        "SQL_UID": SQL_UID,
        "SQL_PWD": SQL_PWD,
    }.items() if not v]
    if missing:
        raise RuntimeError(f".env missing keys: {missing}")

    driver = _pick_driver()
    return (
        f"Driver={{{driver}}};"
        f"Server={SQL_SERVER};"
        f"Database={SQL_DB};"
        f"Uid={SQL_UID};"
        f"Pwd={SQL_PWD};"
        "Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;"
    )


# -----------------------------
# 3) ê³µí†µ ì „ì²˜ë¦¬
# -----------------------------
def coerce_and_enrich(df: pd.DataFrame) -> pd.DataFrame:
    if df is None or df.empty:
        return df

    # ìˆ«ìí˜• ê°•ì œ
    for col in ["rack_tot_cnt", "parking_bike_tot_cnt", "slots_available", "lat", "lon"]:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce")

    # bike_count í†µì¼
    if "parking_bike_tot_cnt" in df.columns:
        df["bike_count"] = pd.to_numeric(df["parking_bike_tot_cnt"], errors="coerce")
    elif "bikes_available" in df.columns:
        df["bike_count"] = pd.to_numeric(df["bikes_available"], errors="coerce")

    # ratio ê³„ì‚°
    if "rack_tot_cnt" in df.columns:
        cap = pd.to_numeric(df["rack_tot_cnt"], errors="coerce")
        if "slots_available" in df.columns:
            df["avail_ratio"] = (pd.to_numeric(df["slots_available"], errors="coerce") / cap).replace([np.inf, -np.inf], np.nan)
        elif "bike_count" in df.columns:
            df["avail_ratio"] = ((cap - df["bike_count"]) / cap).replace([np.inf, -np.inf], np.nan)

        if "bike_count" in df.columns:
            df["occ_ratio"] = (df["bike_count"] / cap).replace([np.inf, -np.inf], np.nan)

    # UTC â†’ KST í‘œì‹œìš© ë¬¸ìì—´ (+09:00 ì œê±°)
    if "ts_utc" in df.columns:
        ts = pd.to_datetime(df["ts_utc"], utc=True, errors="coerce")
        df["ts_kst"] = ts.dt.tz_convert("Asia/Seoul")
        df["ts_kst_str"] = df["ts_kst"].dt.strftime("%Y-%m-%d %H:%M:%S")

    return df


# -----------------------------
# 4) DB ì¡°íšŒ (ìš´ì˜í˜•)
#   - ì»¤ë„¥ì…˜ì€ ë§¤ë²ˆ ìƒˆë¡œ ì—´ê³  ë‹«ìŒ (ëŠê¹€ ë°©ì§€)
#   - ìµœê·¼ Në¶„ë§Œ ì¡°íšŒí•´ì„œ ë¶€í•˜/ëŠê¹€ ê°ì†Œ
# -----------------------------
DEFAULT_LOOKBACK_MINUTES = 60  # ìµœê·¼ 60ë¶„ ë°ì´í„°ë§Œ ì½ê¸°(í•„ìš”ì‹œ ì¡°ì •)

@st.cache_data(ttl=60)
def load_from_sql(lookback_minutes: int = DEFAULT_LOOKBACK_MINUTES):
    conn_str = make_conn_str()
    try:
        with pyodbc.connect(conn_str) as cn:
            # ìµœê·¼ Në¶„ë§Œ
            q_recent = f"""
            SELECT *
            FROM dbo.bike_status
            WHERE ts_utc >= DATEADD(minute, -{int(lookback_minutes)}, SYSUTCDATETIME());
            """
            recent = pd.read_sql(q_recent, cn)

            # ë¶„ì„ ë·° (ìˆìœ¼ë©´)
            try:
                peak = pd.read_sql("SELECT * FROM dbo.vw_station_peak_hours;", cn)
            except Exception:
                peak = pd.DataFrame()

            try:
                reloc = pd.read_sql("SELECT * FROM dbo.vw_relocation_candidate;", cn)
            except Exception:
                reloc = pd.DataFrame()

        return recent, peak, reloc

    except Exception as e:
        st.warning(f"DB ì¡°íšŒ ì‹¤íŒ¨ â†’ CSV ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤. ì‚¬ìœ : {e}")
        return None, None, None


# -----------------------------
# 5) CSV ë°±ì—… ì½ê¸° (fallback)
# -----------------------------
@st.cache_data(ttl=60)
def load_from_csv():
    csv_path = Path("data") / "bike_status_all.csv"
    if not csv_path.exists():
        raise FileNotFoundError(f"CSVê°€ ì—†ìŠµë‹ˆë‹¤: {csv_path}")
    return pd.read_csv(csv_path, encoding="utf-8-sig")


# -----------------------------
# 6) UI ìƒë‹¨ + ë¡œë”©
# -----------------------------
left, mid, right = st.columns([1, 1, 1])
with left:
    st.markdown("### ğŸš² ë”°ë¦‰ì´ ëª¨ë‹ˆí„°ë§ (DB ìš°ì„  / ìš´ì˜í˜•)")
with mid:
    if st.button("ğŸ”„ ë°ì´í„° ìƒˆë¡œê³ ì¹¨"):
        st.cache_data.clear()
        st.success("ë°ì´í„° ìºì‹œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤. 1ë¶„ ë‚´ ìµœì‹  ë°ì´í„°ë¡œ ë‹¤ì‹œ ë¡œë“œë©ë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°”ì—ì„œ lookback ì¡°ì ˆ ê°€ëŠ¥(ì—°ê²° ëŠê¹€/ë¶€í•˜ ì¤„ì´ê¸°)
st.sidebar.header("ë°ì´í„° ë¡œë”© ë²”ìœ„")
lookback = st.sidebar.slider("ìµœê·¼ ì¡°íšŒ ë²”ìœ„(ë¶„)", min_value=10, max_value=360, value=DEFAULT_LOOKBACK_MINUTES, step=10)

recent_df, peak_df, reloc_df = load_from_sql(lookback)

source_label = "SQL (DB ì§ì—°ê²°)"
if recent_df is None:
    # CSVë¡œ ì „í™˜
    try:
        all_df = load_from_csv()
        all_df = coerce_and_enrich(all_df)

        # CSVëŠ” ì „ì²´ì—ì„œ ìµœì‹  ìŠ¤ëƒ…ìƒ·ë§Œ ë§Œë“¤ê¸°
        latest_df = (
            all_df.sort_values("ts_utc", ascending=False)
            .groupby("station_id", as_index=False)
            .first()
        )

        peak_df = pd.DataFrame()
        reloc_df = pd.DataFrame()
        source_label = "CSV (ë°±ì—…)"
    except Exception as e:
        st.error(f"ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        st.stop()
else:
    # DBì—ì„œ ì˜¨ recent_dfë¥¼ "ìŠ¤í…Œì´ì…˜ë³„ ìµœì‹  ìŠ¤ëƒ…ìƒ·"ìœ¼ë¡œ ì¶•ì•½
    recent_df = coerce_and_enrich(recent_df)
    latest_df = (
        recent_df.sort_values("ts_utc", ascending=False)
        .groupby("station_id", as_index=False)
        .first()
    )
    peak_df = coerce_and_enrich(peak_df)
    reloc_df = coerce_and_enrich(reloc_df)


# -----------------------------
# 7) KPI
# -----------------------------
k1, k2, k3, k4 = st.columns(4)
with k1:
    st.metric("ìŠ¤í…Œì´ì…˜ ìˆ˜", f"{latest_df['station_id'].nunique():,}" if "station_id" in latest_df.columns else "N/A")
with k2:
    st.metric("í‰ê·  ê°€ìš©ë¥ ", f"{np.nanmean(latest_df['avail_ratio']):.2f}" if "avail_ratio" in latest_df.columns else "N/A")
with k3:
    if "ts_kst_str" in latest_df.columns and latest_df["ts_kst_str"].notna().any():
        st.metric("ìµœì‹  ì‹œê°(KST)", latest_df["ts_kst_str"].max())
    else:
        st.metric("ìµœì‹  ì‹œê°(KST)", "N/A")
with k4:
    st.metric("ë°ì´í„° ì†ŒìŠ¤", source_label)

st.divider()


# -----------------------------
# 8) í•„í„°
# -----------------------------
st.sidebar.header("í•„í„°")
name_query = st.sidebar.text_input("ëŒ€ì—¬ì†Œëª… ê²€ìƒ‰", value="")

avail_max = float(latest_df["avail_ratio"].quantile(0.95)) if "avail_ratio" in latest_df.columns else 1.0
thresh = st.sidebar.slider("ê°€ìš©ë¥  ì„ê³„ì¹˜(ì´í•˜ë§Œ ë³´ê¸°)", 0.0, 1.0, min(0.2, avail_max), 0.05)

ids = sorted(latest_df["station_id"].dropna().unique().tolist()) if "station_id" in latest_df.columns else []
sel_ids = st.sidebar.multiselect("ëŒ€ì—¬ì†Œ ì„ íƒ", options=ids, default=[])

f = latest_df.copy()
if name_query.strip() and "station_name" in f.columns:
    q = name_query.strip().lower()
    f = f[f["station_name"].astype(str).str.lower().str.contains(q)]
if sel_ids:
    f = f[f["station_id"].isin(sel_ids)]
if "avail_ratio" in f.columns:
    f = f[f["avail_ratio"].astype(float) <= thresh]
if "ts_kst" in f.columns:
    f = f.sort_values("ts_kst", ascending=False)


# -----------------------------
# 9) íƒ­ UI
# -----------------------------
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“‹ í‘œ", "ğŸ—ºï¸ ì§€ë„", "ğŸ“ˆ ì‹œê°„ëŒ€ í˜¼ì¡ë„", "ğŸ“¦ ì¬ë°°ì¹˜ í›„ë³´"])

# ğŸ“‹ í‘œ
with tab1:
    st.markdown("### ìµœì‹  ìŠ¤ëƒ…ìƒ· (í•„í„° ì ìš©)")
    show_cols = [c for c in ["station_id","station_name","bike_count","slots_available","avail_ratio","occ_ratio","rack_tot_cnt","ts_kst_str","lat","lon"] if c in f.columns]
    st.dataframe(display_df(f[show_cols]).head(800), use_container_width=True)

# ğŸ—ºï¸ ì§€ë„
with tab2:
    st.markdown("### ìœ„ì¹˜ ë¶„í¬ (ê°€ìš©ë¥  ìƒ‰/í¬ê¸°)")
    try:
        import pydeck as pdk

        m = f.dropna(subset=["lat", "lon"]).copy()
        if "avail_ratio" in m.columns:
            norm = m["avail_ratio"].clip(0, 1).fillna(0.5)
            m["r"] = (255 * (1 - norm)).astype(int)
            m["g"] = (80 * (1 - abs(norm - 0.5) * 2)).astype(int)
            m["b"] = (255 * norm).astype(int)
            m["size"] = (300 * (1 - norm) + 50).astype(int)
        else:
            m["r"], m["g"], m["b"], m["size"] = 100, 100, 200, 80

        view_state = pdk.ViewState(
            latitude=float(m["lat"].median()) if len(m) else 37.5665,
            longitude=float(m["lon"].median()) if len(m) else 126.9780,
            zoom=11,
        )

        layer = pdk.Layer(
            "ScatterplotLayer",
            data=m,
            get_position="[lon, lat]",
            get_fill_color="[r, g, b]",
            get_radius="size",
            pickable=True,
        )

        st.pydeck_chart(
            pdk.Deck(
                layers=[layer],
                initial_view_state=view_state,
                tooltip={"text": "{station_name}\nê°€ìš©ë¥ : {avail_ratio}"},
            )
        )
    except Exception:
        st.info("pydeckì„ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ st.mapìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        if {"lat", "lon"}.issubset(f.columns):
            st.map(f.rename(columns={"lat": "latitude", "lon": "longitude"})[["latitude", "longitude"]])

# ğŸ“ˆ ì‹œê°„ëŒ€ í˜¼ì¡ë„
with tab3:
    st.markdown("### ì‹œê°„ëŒ€ë³„ í‰ê·  ê°€ìš©ë¥ /ì ìœ ìœ¨ (KST ê¸°ì¤€)")
    if not peak_df.empty:
        peak_work = peak_df.copy()
        if "hour_utc" in peak_work.columns:
            h = pd.to_numeric(peak_work["hour_utc"], errors="coerce")
            peak_work["hour_kst"] = (h + 9) % 24
        else:
            peak_work["hour_kst"] = np.nan

        peak_work = peak_work.sort_values("hour_kst")
        st.dataframe(display_df(peak_work), use_container_width=True, height=320)

        if "availability_pct" in peak_work.columns:
            fig = plt.figure()
            plt.plot(peak_work["hour_kst"], peak_work["availability_pct"])
            plt.title("ì‹œê°„ëŒ€ë³„ í‰ê·  ê°€ìš©ë¥  (KST)")
            plt.xlabel("ì‹œê°„ (KST)")
            plt.ylabel("í‰ê·  ê°€ìš©ë¥ (%)")
            plt.xticks(range(0, 24, 2))
            st.pyplot(fig)
    else:
        st.info("vw_station_peak_hours ë·°ê°€ ì—†ì–´ ì°¨íŠ¸ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ğŸ“¦ ì¬ë°°ì¹˜ í›„ë³´
with tab4:
    st.markdown("### ì¬ë°°ì¹˜ í›„ë³´")
    if not reloc_df.empty:
        st.dataframe(display_df(reloc_df), use_container_width=True)
    else:
        st.info("vw_relocation_candidate ë·°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

# CSV ë‹¤ìš´ë¡œë“œ
st.download_button(
    "ğŸ“¥ í˜„ì¬ ëª©ë¡ CSVë¡œ ë‹¤ìš´ë¡œë“œ (í•œê¸€ ì»¬ëŸ¼)",
    display_df(f).to_csv(index=False).encode("utf-8-sig"),
    "bike_status_current_kor.csv",
)

st.caption("ë°ì´í„° ì†ŒìŠ¤: Azure SQL (ìµœê·¼ Në¶„ ì¡°íšŒ â†’ ìµœì‹  ìŠ¤ëƒ…ìƒ·), í‘œì‹œ: UTCâ†’KST / ì‹¤íŒ¨ ì‹œ CSV")
